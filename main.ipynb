{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from math import floor\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import os\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_data = pd.read_csv(\"train_v2.csv\")\n",
    "#data = np.array(np.zeros((500,256,256,3)),dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def DataLoader(data,batch_size = 10):\n",
    "#    i = 0\n",
    "#    ret_data = []\n",
    "#    while True:\n",
    "#        \n",
    "#        if i+batch_size > images_names.shape[0]:\n",
    "#            get_data = images_names[i:]\n",
    "#            i=0\n",
    "#        else:\n",
    "#            get_data = images_names[i:i+batch_size]\n",
    "#            i += batch_size\n",
    "#            \n",
    "#        for image in get_data:\n",
    "#            ret_data.append(plt.imread(\"train-jpg/%s.jpg\" % image)[:,:,0:3].reshape(3,256,256))#\n",
    "#\n",
    "#        \n",
    "#        yield torch.from_numpy(np.array(ret_data).astype('float32')).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_valid_split(dataframe, test_size = 0.25, shuffle = False, random_seed = 0):\n",
    "    \"\"\" Return a list of splitted indices from a DataSet.\n",
    "    Indices can be used with DataLoader to build a train and validation set.\n",
    "    \n",
    "    Arguments:\n",
    "        A Dataframe\n",
    "        A test_size, as a float between 0 and 1 (percentage split) or as an int (fixed number split)\n",
    "        Shuffling True or False\n",
    "        Random seed\n",
    "    \"\"\"\n",
    "    length = len(dataframe)\n",
    "    indices = list(range(1,length))\n",
    "    \n",
    "    if shuffle == True:\n",
    "        random.seed(random_seed)\n",
    "        random.shuffle(indices)\n",
    "    \n",
    "    if type(test_size) is float:\n",
    "        split = floor(test_size * length)\n",
    "    elif type(test_size) is int:\n",
    "        split = test_size\n",
    "    else:\n",
    "        raise ValueError('%s should be an int or a float' % str)\n",
    "    return indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KaggleAmazonDataset(Dataset):\n",
    "    \"\"\"Dataset wrapping images and target labels for Kaggle - Planet Amazon from Space competition.\n",
    "\n",
    "    Arguments:\n",
    "        A CSV file path\n",
    "        Path to image folder\n",
    "        Extension of images\n",
    "        PIL transforms\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_path, img_path, img_ext, transform=None):\n",
    "    \n",
    "        tmp_df = pd.read_csv(csv_path)\n",
    "        assert tmp_df['image_name'].apply(lambda x: os.path.isfile(img_path + x + img_ext)).all(), \\\n",
    "\"Some images referenced in the CSV file were not found\"\n",
    "        \n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.img_path = img_path\n",
    "        self.img_ext = img_ext\n",
    "        self.transform = transform\n",
    "\n",
    "        self.X_train = tmp_df['image_name']\n",
    "        self.y_train = self.mlb.fit_transform(tmp_df['tags'].str.split()).astype(np.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path + self.X_train[index] + self.img_ext)\n",
    "        img = img.convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img).cuda()\n",
    "        \n",
    "        label = torch.from_numpy(self.y_train[index]).cuda()\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = DataLoader(csv_data[\"image_name\"])\n",
    "#label = DataLoader(csv_data[\"tags\"])\n",
    "#for i,data in enumerate(data):\n",
    "    #print(i),print(data)\n",
    "IMG_PATH = 'train-jpg/'\n",
    "IMG_EXT = '.jpg'\n",
    "TRAIN_DATA = 'train_v2.csv'\n",
    "#transformations = transforms.Compose([transforms.Scale(32),transforms.ToTensor()])\n",
    "#dset_train = KaggleAmazonDataset(TRAIN_DATA,IMG_PATH,IMG_EXT,transformations)\n",
    "\n",
    "\n",
    "## Augmentation + Normalization for full training\n",
    "ds_transform_augmented = transforms.Compose([\n",
    "                 transforms.RandomSizedCrop(224),\n",
    "                 #transforms.Scale(512),\n",
    "                 transforms.RandomHorizontalFlip(), \n",
    "                 transforms.ToTensor(),\n",
    "                 #transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                # std=[0.229, 0.224, 0.225]),\n",
    "\n",
    "                 # Affine(\n",
    "                 #     rotation_range = 15,\n",
    "                 #     translation_range = (0.2,0.2),\n",
    "                 #     shear_range = math.pi/6,\n",
    "                 #     zoom_range=(0.7,1.4)\n",
    "                 # )\n",
    "                ])\n",
    "\n",
    "## Normalization only for validation and test\n",
    "ds_transform_raw = transforms.Compose([\n",
    "                 transforms.Scale(224),\n",
    "                 transforms.ToTensor(),\n",
    "                 transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.02, 0.02, 0.225])\n",
    "                 ])\n",
    "\n",
    "####     #########     ########     ###########     #####\n",
    "\n",
    "X_train = KaggleAmazonDataset(TRAIN_DATA,IMG_PATH,IMG_EXT,\n",
    "                             ds_transform_augmented\n",
    "                             )\n",
    "X_val = KaggleAmazonDataset(TRAIN_DATA,IMG_PATH,IMG_EXT,\n",
    "                             ds_transform_raw\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a validation split\n",
    "train_idx, valid_idx = train_valid_split(X_train, 0.2)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = DataLoader(X_train,\n",
    "                          batch_size=2,\n",
    "                          sampler=train_sampler,\n",
    "                          #num_workers=4,\n",
    "                          #pin_memory= True\n",
    "                         )\n",
    "\n",
    "valid_loader = DataLoader(X_val,\n",
    "                          batch_size=2,\n",
    "                          sampler=valid_sampler,\n",
    "                          #num_workers=4,\n",
    "                         #pin_memory= True\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adaptive_avgmax_pool2d(x, pool_type='avg', padding=0, count_include_pad=False):\n",
    "    \"\"\"Selectable global pooling function with dynamic input kernel size\n",
    "    \"\"\"\n",
    "    if pool_type == 'avgmaxc':\n",
    "        x = torch.cat([\n",
    "            F.avg_pool2d(\n",
    "                x, kernel_size=(x.size(2), x.size(3)), padding=padding, count_include_pad=count_include_pad),\n",
    "            F.max_pool2d(x, kernel_size=(x.size(2), x.size(3)), padding=padding)\n",
    "        ], dim=1)\n",
    "    elif pool_type == 'avgmax':\n",
    "        x_avg = F.avg_pool2d(\n",
    "                x, kernel_size=(x.size(2), x.size(3)), padding=padding, count_include_pad=count_include_pad)\n",
    "        x_max = F.max_pool2d(x, kernel_size=(x.size(2), x.size(3)), padding=padding)\n",
    "        x = 0.5 * (x_avg + x_max)\n",
    "    elif pool_type == 'max':\n",
    "        x = F.max_pool2d(x, kernel_size=(x.size(2), x.size(3)), padding=padding)\n",
    "    else:\n",
    "        if pool_type != 'avg':\n",
    "            print('Invalid pool type %s specified. Defaulting to average pooling.' % pool_type)\n",
    "        x = F.avg_pool2d(\n",
    "            x, kernel_size=(x.size(2), x.size(3)), padding=padding, count_include_pad=count_include_pad)\n",
    "    return x\n",
    "\n",
    "def pooling_factor(pool_type='avg'):\n",
    "    return 2 if pool_type == 'avgmaxc' else 1\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152']\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, drop_rate=0.0):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        if self.drop_rate > 0.:\n",
    "            out = F.dropout(out, p=self.drop_rate, training=self.training)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, drop_rate=0.0):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        if self.drop_rate > 0.:\n",
    "            out = F.dropout(out, p=self.drop_rate, training=self.training)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000,\n",
    "                 drop_rate=0.0, block_drop_rate=0.0,\n",
    "                 global_pool='avg'):\n",
    "        self.inplanes = 64\n",
    "        self.drop_rate = drop_rate\n",
    "        self.expansion = block.expansion\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], drop_rate=block_drop_rate)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, drop_rate=block_drop_rate)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, drop_rate=block_drop_rate)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, drop_rate=block_drop_rate)\n",
    "        self.global_pool = AdaptiveAvgMaxPool2d(pool_type=global_pool)\n",
    "        self.fc = nn.Linear(512 * block.expansion * self.global_pool.factor(), num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, drop_rate=0.):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = [block(self.inplanes, planes, stride, downsample, drop_rate)]\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def get_fc(self):\n",
    "        return self.fc\n",
    "\n",
    "    def reset_fc(self, num_classes, global_pool='avg'):\n",
    "        self.global_pool = AdaptiveAvgMaxPool2d(pool_type=global_pool)\n",
    "        self.fc = nn.Linear(512 * self.expansion * self.global_pool.factor(), num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        if self.drop_rate > 0.:\n",
    "            x = F.dropout(x, p=self.drop_rate, training=self.training)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'imagenet': 'http://webia.lip6.fr/~cadene/Downloads/inceptionv4-97ef9c30.pth'\n",
    "}\n",
    "\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Mixed_3a(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mixed_3a, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d(3, stride=2)\n",
    "        self.conv = BasicConv2d(64, 96, kernel_size=3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.maxpool(x)\n",
    "        x1 = self.conv(x)\n",
    "        out = torch.cat((x0, x1), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Mixed_4a(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mixed_4a, self).__init__()\n",
    "\n",
    "        self.branch0 = nn.Sequential(\n",
    "            BasicConv2d(160, 64, kernel_size=1, stride=1),\n",
    "            BasicConv2d(64, 96, kernel_size=3, stride=1)\n",
    "        )\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(160, 64, kernel_size=1, stride=1),\n",
    "            BasicConv2d(64, 64, kernel_size=(1, 7), stride=1, padding=(0, 3)),\n",
    "            BasicConv2d(64, 64, kernel_size=(7, 1), stride=1, padding=(3, 0)),\n",
    "            BasicConv2d(64, 96, kernel_size=(3, 3), stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        out = torch.cat((x0, x1), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Mixed_5a(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mixed_5a, self).__init__()\n",
    "        self.conv = BasicConv2d(192, 192, kernel_size=3, stride=2)\n",
    "        self.maxpool = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.conv(x)\n",
    "        x1 = self.maxpool(x)\n",
    "        out = torch.cat((x0, x1), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Inception_A(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Inception_A, self).__init__()\n",
    "        self.branch0 = BasicConv2d(384, 96, kernel_size=1, stride=1)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(384, 64, kernel_size=1, stride=1),\n",
    "            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(384, 64, kernel_size=1, stride=1),\n",
    "            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(96, 96, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
    "            BasicConv2d(384, 96, kernel_size=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Reduction_A(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Reduction_A, self).__init__()\n",
    "        self.branch0 = BasicConv2d(384, 384, kernel_size=3, stride=2)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(384, 192, kernel_size=1, stride=1),\n",
    "            BasicConv2d(192, 224, kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(224, 256, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        out = torch.cat((x0, x1, x2), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Inception_B(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Inception_B, self).__init__()\n",
    "        self.branch0 = BasicConv2d(1024, 384, kernel_size=1, stride=1)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n",
    "            BasicConv2d(192, 224, kernel_size=(1, 7), stride=1, padding=(0, 3)),\n",
    "            BasicConv2d(224, 256, kernel_size=(7, 1), stride=1, padding=(3, 0))\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n",
    "            BasicConv2d(192, 192, kernel_size=(7, 1), stride=1, padding=(3, 0)),\n",
    "            BasicConv2d(192, 224, kernel_size=(1, 7), stride=1, padding=(0, 3)),\n",
    "            BasicConv2d(224, 224, kernel_size=(7, 1), stride=1, padding=(3, 0)),\n",
    "            BasicConv2d(224, 256, kernel_size=(1, 7), stride=1, padding=(0, 3))\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
    "            BasicConv2d(1024, 128, kernel_size=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Reduction_B(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Reduction_B, self).__init__()\n",
    "\n",
    "        self.branch0 = nn.Sequential(\n",
    "            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n",
    "            BasicConv2d(192, 192, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(1024, 256, kernel_size=1, stride=1),\n",
    "            BasicConv2d(256, 256, kernel_size=(1, 7), stride=1, padding=(0, 3)),\n",
    "            BasicConv2d(256, 320, kernel_size=(7, 1), stride=1, padding=(3, 0)),\n",
    "            BasicConv2d(320, 320, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        out = torch.cat((x0, x1, x2), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Inception_C(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Inception_C, self).__init__()\n",
    "\n",
    "        self.branch0 = BasicConv2d(1536, 256, kernel_size=1, stride=1)\n",
    "\n",
    "        self.branch1_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n",
    "        self.branch1_1a = BasicConv2d(384, 256, kernel_size=(1, 3), stride=1, padding=(0, 1))\n",
    "        self.branch1_1b = BasicConv2d(384, 256, kernel_size=(3, 1), stride=1, padding=(1, 0))\n",
    "\n",
    "        self.branch2_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n",
    "        self.branch2_1 = BasicConv2d(384, 448, kernel_size=(3, 1), stride=1, padding=(1, 0))\n",
    "        self.branch2_2 = BasicConv2d(448, 512, kernel_size=(1, 3), stride=1, padding=(0, 1))\n",
    "        self.branch2_3a = BasicConv2d(512, 256, kernel_size=(1, 3), stride=1, padding=(0, 1))\n",
    "        self.branch2_3b = BasicConv2d(512, 256, kernel_size=(3, 1), stride=1, padding=(1, 0))\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
    "            BasicConv2d(1536, 256, kernel_size=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "\n",
    "        x1_0 = self.branch1_0(x)\n",
    "        x1_1a = self.branch1_1a(x1_0)\n",
    "        x1_1b = self.branch1_1b(x1_0)\n",
    "        x1 = torch.cat((x1_1a, x1_1b), 1)\n",
    "\n",
    "        x2_0 = self.branch2_0(x)\n",
    "        x2_1 = self.branch2_1(x2_0)\n",
    "        x2_2 = self.branch2_2(x2_1)\n",
    "        x2_3a = self.branch2_3a(x2_2)\n",
    "        x2_3b = self.branch2_3b(x2_2)\n",
    "        x2 = torch.cat((x2_3a, x2_3b), 1)\n",
    "\n",
    "        x3 = self.branch3(x)\n",
    "\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class InceptionV4(nn.Module):\n",
    "    def __init__(self, num_classes=1001, drop_rate=0., global_pool='avg'):\n",
    "        super(InceptionV4, self).__init__()\n",
    "        self.drop_rate = drop_rate\n",
    "        self.global_pool = global_pool\n",
    "        self.features = nn.Sequential(\n",
    "            BasicConv2d(3, 32, kernel_size=3, stride=2),\n",
    "            BasicConv2d(32, 32, kernel_size=3, stride=1),\n",
    "            BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            Mixed_3a(),\n",
    "            Mixed_4a(),\n",
    "            Mixed_5a(),\n",
    "            Inception_A(),\n",
    "            Inception_A(),\n",
    "            Inception_A(),\n",
    "            Inception_A(),\n",
    "            Reduction_A(),  # Mixed_6a\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Reduction_B(),  # Mixed_7a\n",
    "            Inception_C(),\n",
    "            Inception_C(),\n",
    "            Inception_C(),\n",
    "        )\n",
    "        self.classif = nn.Linear(1536 * pooling_factor(global_pool), num_classes)\n",
    "\n",
    "    def get_fc(self):\n",
    "        return self.classif\n",
    "\n",
    "    def reset_fc(self, num_classes, global_pool='avg'):\n",
    "        self.global_pool = global_pool\n",
    "        self.classif = nn.Linear(1536 * pooling_factor(global_pool), num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = adaptive_avgmax_pool2d(x, self.global_pool, count_include_pad=False)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        if self.drop_rate > 0:\n",
    "            x = F.dropout(x, p=self.drop_rate, training=self.training)\n",
    "        x = self.classif(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def inception_v4(pretrained=False, num_classes=1001, **kwargs):\n",
    "    model = InceptionV4(num_classes=num_classes, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['imagenet']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveAvgMaxPool2d(torch.nn.Module):\n",
    "    \"\"\"Selectable global pooling layer with dynamic input kernel size\n",
    "    \"\"\"\n",
    "    def __init__(self, output_size=1, pool_type='avg'):\n",
    "        super(AdaptiveAvgMaxPool2d, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.pool_type = pool_type\n",
    "        if pool_type == 'avgmaxc' or pool_type == 'avgmax':\n",
    "            self.pool = nn.ModuleList([nn.AdaptiveAvgPool2d(output_size), nn.AdaptiveMaxPool2d(output_size)])\n",
    "        elif pool_type == 'max':\n",
    "            self.pool = nn.AdaptiveMaxPool2d(output_size)\n",
    "        else:\n",
    "            if pool_type != 'avg':\n",
    "                print('Invalid pool type %s specified. Defaulting to average pooling.' % pool_type)\n",
    "            self.pool = nn.AdaptiveAvgPool2d(output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.pool_type == 'avgmaxc':\n",
    "            x = torch.cat([p(x) for p in self.pool], dim=1)\n",
    "        elif self.pool_type == 'avgmax':\n",
    "            x = 0.5 * torch.sum(torch.stack([p(x) for p in self.pool]), 0).squeeze(dim=0)\n",
    "        else:\n",
    "            x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "    def factor(self):\n",
    "        return pooling_factor(self.pool_type)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + 'output_size=' + str(self.output_size) \\\n",
    "+ ', pool_type=' + self.pool_type + ')'\n",
    "\n",
    "#model = Net()\n",
    "#model = models.inception_v3(num_classes=17, aux_logits=False, transform_input = True)\n",
    "#model = models.vgg16(pretrained=True, num_classes=17)\n",
    "#model = resnet50(num_classes=17)\n",
    "model = inception_v4(pretrained=True)\n",
    "model.reset_fc(17)\n",
    "optimizer = optim.RMSprop(model.parameters(),lr=0.00001)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.0001)\n",
    "criterion = nn.MultiLabelSoftMarginLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    return fbeta_score(output, target, beta=2, average=\"samples\")\n",
    "\n",
    "def train_generator(model,epoch,train_loader,optimizer,criterion):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            #data, target = data.cuda(async=True), target.cuda(async=True) # On GPU\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 10000 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "                \n",
    "def test_generator(model, val_loader, criterion):\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        ammount = 0\n",
    "        equal = 0\n",
    "        pred_all = None\n",
    "        test_all = None\n",
    "        test = 0\n",
    "        for data, target in val_loader:\n",
    "            data, target = Variable(data.float(), volatile=True), Variable(target.float())\n",
    "            output = model(data)\n",
    "            ammount += len(data)\n",
    "            test_loss += criterion(output, target).data[0]\n",
    "            pred = output\n",
    "            pred[pred > 0.5] = 1\n",
    "            pred[pred != 1] = 0\n",
    "\n",
    "            if type(pred_all) == type(None):\n",
    "                pred_all = pred.cpu().data.numpy().astype(np.uint8)\n",
    "            else:\n",
    "                pred = pred.cpu().data.numpy().astype(np.uint8)\n",
    "\n",
    "                pred_all = np.concatenate((pred_all,pred),axis=0)\n",
    "            if type(test_all) == type(None):\n",
    "                test_all = target.cpu().data.numpy().astype(np.uint8)\n",
    "            else:\n",
    "                target = target.cpu().data.numpy().astype(np.uint8)\n",
    "                test_all = np.concatenate((test_all,target),axis=0)\n",
    "            test += 1\n",
    "            #accuracy(output, target,topk=(1,3))\n",
    "            if test > 10:\n",
    "                break\n",
    "        test_loss /= ammount\n",
    "        print('Test set: Accuracy: %s\\n' % accuracy(pred_all,test_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/40479 (0%)]\tLoss: 0.735852\n",
      "Train Epoch: 1 [20000/40479 (62%)]\tLoss: 0.319800\n",
      "Test set: Accuracy: 0.644223219591\n",
      "\n",
      "Train Epoch: 2 [0/40479 (0%)]\tLoss: 0.103249\n",
      "Train Epoch: 2 [20000/40479 (62%)]\tLoss: 0.145181\n",
      "Test set: Accuracy: 0.339237234\n",
      "\n",
      "Train Epoch: 3 [0/40479 (0%)]\tLoss: 0.197381\n",
      "Train Epoch: 3 [20000/40479 (62%)]\tLoss: 0.135913\n",
      "Test set: Accuracy: 0.522890134182\n",
      "\n",
      "Train Epoch: 4 [0/40479 (0%)]\tLoss: 0.060732\n",
      "Train Epoch: 4 [20000/40479 (62%)]\tLoss: 0.025474\n",
      "Test set: Accuracy: 0.531850459482\n",
      "\n",
      "Train Epoch: 5 [0/40479 (0%)]\tLoss: 0.269520\n",
      "Train Epoch: 5 [20000/40479 (62%)]\tLoss: 0.311245\n",
      "Test set: Accuracy: 0.399543358486\n",
      "\n",
      "Train Epoch: 6 [0/40479 (0%)]\tLoss: 0.171892\n",
      "Train Epoch: 6 [20000/40479 (62%)]\tLoss: 0.010325\n",
      "Test set: Accuracy: 0.463200283834\n",
      "\n",
      "Train Epoch: 7 [0/40479 (0%)]\tLoss: 0.015730\n",
      "Train Epoch: 7 [20000/40479 (62%)]\tLoss: 0.035542\n",
      "Test set: Accuracy: 0.440988137679\n",
      "\n",
      "Train Epoch: 8 [0/40479 (0%)]\tLoss: 0.221232\n",
      "Train Epoch: 8 [20000/40479 (62%)]\tLoss: 0.280891\n",
      "Test set: Accuracy: 0.525001380863\n",
      "\n",
      "Train Epoch: 9 [0/40479 (0%)]\tLoss: 0.289437\n",
      "Train Epoch: 9 [20000/40479 (62%)]\tLoss: 0.032585\n",
      "Test set: Accuracy: 0.35447701808\n",
      "\n",
      "Train Epoch: 10 [0/40479 (0%)]\tLoss: 0.168894\n",
      "Train Epoch: 10 [20000/40479 (62%)]\tLoss: 0.161478\n",
      "Test set: Accuracy: 0.418499986942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.DataParallel(model).cuda()\n",
    "for epoch in range(1, 10 + 1):\n",
    "    train_generator(model,epoch,train_loader,optimizer,criterion)\n",
    "    test_generator(model,valid_loader,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954545454545\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
